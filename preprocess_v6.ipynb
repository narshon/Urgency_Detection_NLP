{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing V6 Datasets - Re-labelling the target variable\n",
    "\n",
    "For Task 14 and Task 15, the target variable, \"label\", will be regenerated using the criteria:\n",
    "- Reclassify urgent as 1,2,3 labels and not urgent as 4 & 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46303 entries, 0 to 46302\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   mid      46303 non-null  int64 \n",
      " 1   Urgency  46303 non-null  int64 \n",
      " 2   text     46303 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "system_context_all = pd.read_csv(\"Data/system_context_all_v5.csv\")\n",
    "system_context_all.rename(columns={\"ID_x\":\"mid\", \"contextualized\":\"text\"}, inplace=True)\n",
    "system_context_all = system_context_all[[\"mid\",\"Urgency\",\"text\"]]\n",
    "system_context_all.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2    36651\n",
       " 0     5081\n",
       " 1     4571\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Reclassify urgent as 1,2,3 labels and not urgent as 4 & 5.\n",
    "\n",
    "messages_df = system_context_all.assign(label = np.where( ((system_context_all.Urgency == 1) | (system_context_all.Urgency == 2) |\n",
    "                                                          (system_context_all.Urgency == 3)), 1, \n",
    "                                                         np.where(((system_context_all.Urgency == 4) | (system_context_all.Urgency == 5)), 0, -2 )\n",
    "                                                        ))\n",
    "messages_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. generate datasets\n",
    "\n",
    "#get unlabeled system_context messages\n",
    "system_context_unlbl = messages_df[messages_df.label < 0]\n",
    "system_context_unlbl.to_csv(\"Data/system_context_all_unlbl_v6.csv\")\n",
    "\n",
    "#get labeled system_context messages\n",
    "system_context_lbl = messages_df[messages_df.label >= 0]\n",
    "system_context_lbl.to_csv(\"Data/system_context_all_lbl_v6.csv\")\n",
    "\n",
    "#System Context train test split\n",
    "train_df, remain_df = train_test_split(system_context_lbl, random_state=42, train_size=0.7, stratify=system_context_lbl.label.values)\n",
    "test_df, dev_df = train_test_split(remain_df, random_state=42, train_size=0.7, stratify=remain_df.label.values)\n",
    "\n",
    "train_df.to_csv(\"Data/train_df_v6.csv\")\n",
    "test_df.to_csv(\"Data/test_df_v6.csv\")\n",
    "dev_df.to_csv(\"Data/dev_df_v6.csv\")\n",
    "\n",
    "#formulate system context pretraining dataset\n",
    "system_context_pretrain_df = pd.concat([system_context_unlbl, train_df])\n",
    "system_context_pretrain_df.to_csv(\"Data/system_context_pretrain_v6.csv\")\n",
    "system_pretrain_train, system_pretrain_validation = train_test_split(system_context_pretrain_df, test_size=0.2, random_state=42)\n",
    "system_pretrain_train.text.to_csv(\"Data/system_pretrain_train_v6.csv\")\n",
    "system_pretrain_validation.text.to_csv(\"Data/system_pretrain_dev_v6.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Pretraining sets on labeled data\n",
    "#remove test set from all labeled dataset\n",
    "pretrain_lbl_df = system_context_lbl[~system_context_lbl.mid.isin(list(test_df.mid)) ]\n",
    "\n",
    "system_pretrain_train_lbl, system_pretrain_dev_lbl = train_test_split(pretrain_lbl_df, test_size=0.2, random_state=42)\n",
    "\n",
    "system_pretrain_train_lbl.text.to_csv(\"Data/system_pretrain_train_lbl_v6.csv\")\n",
    "system_pretrain_dev_lbl.text.to_csv(\"Data/system_pretrain_dev_lbl_v6.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
