{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA of larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (15,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "messages_df = pd.read_csv(\"../NEO-RCT-labeled/mwach-dump-2022-04-05/mwbase_message-2022-04-05.csv\")\n",
    "\n",
    "#Remove messages with no participants -- spam\n",
    "messages_df = messages_df[messages_df.participant_id.notnull()]\n",
    "\n",
    "#Sort by participant and date\n",
    "messages_df = messages_df.sort_values(by=['participant_id', 'created'], ascending=[True, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate sent_by and select variables of importance\n",
    "messages_df['sent_by'] = np.where(messages_df.System == 1, 'system', \n",
    "                                  np.where((messages_df.Out == 1) & (messages_df.System == 0), 'nurse', 'participant'))\n",
    "\n",
    "messages_final = messages_df[['ID','created','Out','System','languages','participant_id', 'Message Urgency','sent_by', 'text']]\n",
    "\n",
    "#rename urgency column\n",
    "messages_final = messages_final.rename(columns={'Message Urgency':'Urgency'})\n",
    "\n",
    "#create label variable\n",
    "messages_final['label'] = np.where(((messages_final.Urgency == 1) | (messages_final.Urgency == 2)), 1,\n",
    "                                  np.where((messages_final.Urgency == 3) | (messages_final.Urgency == 4) | (messages_final.Urgency == 5), 0, -2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info\n",
    "messages_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!{sys.executable} -m pip install pandas-profiling\n",
    "#Describe\n",
    "#messages_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install --upgrade IProgress\n",
    "#!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2    159454\n",
       " 5      3682\n",
       " 3      2334\n",
       " 2      1786\n",
       " 4      1399\n",
       " 1       451\n",
       "Name: Urgency, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_final['Urgency'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    93160\n",
       "0    75946\n",
       "Name: System, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df['System'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    122443\n",
       "0     46663\n",
       "Name: Out, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df.Out.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "system         93160\n",
       "participant    46663\n",
       "nurse          29283\n",
       "Name: sent_by, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_df.sent_by.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2    159454\n",
       " 0      7415\n",
       " 1      2237\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_final.label.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save raw dataset\n",
    "messages_final.to_csv(\"Data/messages_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate json of names for removing in message texts\n",
    "participant =  pd.read_csv(\"../NEO-RCT-labeled/mwach-dump-2022-04-05/mwneo_participant-2022-04-05.csv\")\n",
    "\n",
    "json_string = participant['SMS Name'].to_json(orient='values')\n",
    "# Using a JSON string\n",
    "with open('Data/names2.json', 'w') as outfile:\n",
    "    outfile.write(json_string)\n",
    "\n",
    "# Functions\n",
    "def removeNames(df, text_column, json_file):\n",
    "    # Opening JSON file\n",
    "    f = open(json_file,)\n",
    "    # returns JSON object\n",
    "    names = json.load(f)\n",
    "\n",
    "    p = re.compile('|'.join(map(re.escape, names)))\n",
    "    df[text_column] = [p.sub('', str(text)) for text in df[text_column]]\n",
    "\n",
    "    return df\n",
    "    \n",
    "def removeSalutation(row, text_column):\n",
    "    ''' #Remove salutation '''\n",
    "    sent = str(row[text_column])\n",
    "    result = re.match(r\".+, this is \\b[A-Z][a-z]+ from \\b[A-Z][a-z]+\", sent)\n",
    "    result_swahili = re.match(r\".+, huyu ni \\b[A-Z][a-z]+ kutoka \\b[A-Z][a-z]+\", sent)\n",
    "    result_luo = re.match(r\".+, mae en \\b[A-Z][a-z]+ mawuok \\b[A-Z][a-z]+\", sent)\n",
    "    result_welcome = re.match(r\".+Welcome to Mobile WACh NEO \\b[A-Z][a-z]+\", sent)\n",
    "    result_karibu = re.match(r\".+Karibu kwa Mobile WACh NEO \\b[A-Z][a-z]+\", sent)\n",
    "    #mobile WACh NEO\n",
    "    result_wachneo = re.match(r\".+ mobile WACh NEO \\b[A-Z][a-z]+\", sent)\n",
    "    result_wachcaps = re.match(r\".+ Mobile WACh NEO \\b[A-Z][a-z]+\", sent)\n",
    "\n",
    "    if(result):\n",
    "        sentence = sent.split(str(result.group()),1)[1]\n",
    "    elif(result_swahili):\n",
    "        sentence = sent.split(str(result_swahili.group()),1)[1]\n",
    "    elif(result_luo):\n",
    "        sentence = sent.split(str(result_luo.group()),1)[1]\n",
    "    elif(result_wachneo):\n",
    "        sentence = sent.split(str(result_wachneo.group()),1)[1]\n",
    "    elif(result_welcome):\n",
    "        sentence = sent.split(str(result_welcome.group()),1)[1]\n",
    "    elif(result_karibu):\n",
    "        sentence = sent.split(str(result_karibu.group()),1)[1]\n",
    "    elif(result_wachcaps):\n",
    "        sentence = sent.split(str(result_wachcaps.group()),1)[1]\n",
    "    else:\n",
    "        sentence = sent\n",
    "\n",
    "    return sentence\n",
    "\n",
    "def removePunctuations(row, column):\n",
    "    texts = str(row[column])\n",
    "    #print(texts)\n",
    "    for punctuation in string.punctuation:\n",
    "        #print(punctuation)\n",
    "        texts = texts.replace(punctuation, '')\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant['SMS Name'].to_csv(\"Data/participant_names2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import string \n",
    "\n",
    "#1. remove salutations\n",
    "text_column = \"text\"\n",
    "maindf = messages_final\n",
    "maindf = maindf.assign(text = maindf.apply(lambda row: removeSalutation(row, text_column), axis=1))\n",
    "\n",
    "#2. remove punctuation marks\n",
    "text_column = \"text\"\n",
    "maindf = maindf.assign(text = maindf.apply(lambda row: removePunctuations(row, text_column), axis=1))\n",
    "\n",
    "#3. remove names\n",
    "maindf = removeNames(maindf, 'text', \"Data/names.json\")\n",
    "maindf = removeNames(maindf, 'text', \"Data/names2.json\")\n",
    "\n",
    "#4. remove validation messages\n",
    "#maindf = maindf[maindf['topic'] != \"validation\"]\n",
    "\n",
    "maindf_short = maindf[['ID','created','Out','System','languages','participant_id', 'Urgency','sent_by', 'text', 'label']]\n",
    "maindf_short = maindf_short.reset_index()\n",
    "\n",
    "#Write to current folder\n",
    "maindf_short.to_csv(\"Data/main_df_v4.csv\")\n",
    "\n",
    "#5. Generate context_id for System context\n",
    "maindf_short['context_id'] = 0\n",
    "context_id = 0\n",
    "i = 0\n",
    "for row in maindf_short.itertuples():\n",
    "    if(row.sent_by == \"system\"):\n",
    "        context_id = row.ID\n",
    "    #maindf_short.set_value(i, \"context_id\", context_id)\n",
    "    maindf_short.at[i, 'context_id'] = context_id\n",
    "    i += 1\n",
    "\n",
    "#6. System messages\n",
    "system_df = maindf_short[maindf_short['sent_by'] == 'system']\n",
    "system_df = system_df[[\"ID\", \"text\"]]\n",
    "system_df['system_text'] = system_df.text\n",
    "system_df = system_df[[\"ID\", \"system_text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a1c938dea95c>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  participant_context['mid'] = participant_context.ID_x\n",
      "<ipython-input-11-a1c938dea95c>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  participant_context['text'] = participant_context.contextualized\n"
     ]
    }
   ],
   "source": [
    "#7. Participants messages - System Context\n",
    "participant_df = maindf_short[maindf_short['sent_by'] == 'participant']\n",
    "#Participants - add system context\n",
    "part_context = pd.merge(participant_df, system_df, how=\"left\", left_on=\"context_id\", right_on=\"ID\")\n",
    "#dealing with all messages, including those without preceding context\n",
    "part_context['contextualized'] = np.where(part_context.context_id == 0, part_context.text, part_context.system_text+\" \"+part_context.text)\n",
    "\n",
    "participant_context = part_context[['ID_x', 'participant_id', 'contextualized', 'label']]\n",
    "participant_context['mid'] = participant_context.ID_x\n",
    "participant_context['text'] = participant_context.contextualized\n",
    "participant_context = participant_context[['mid', 'participant_id', 'text', 'label']]\n",
    "\n",
    "#get unlabeled system_context messages\n",
    "system_context_unlbl = participant_context[participant_context.label < 0]\n",
    "system_context_unlbl.to_csv(\"Data/system_context_all_unlbl_v4.csv\")\n",
    "\n",
    "#get labeled system_context messages\n",
    "system_context_lbl = participant_context[participant_context.label >= 0]\n",
    "system_context_lbl.to_csv(\"Data/system_context_all_lbl_v4.csv\")\n",
    "\n",
    "#System Context train test split\n",
    "train_df, remain_df = train_test_split(system_context_lbl, random_state=42, train_size=0.7, stratify=system_context_lbl.label.values)\n",
    "test_df, dev_df = train_test_split(remain_df, random_state=42, train_size=0.7, stratify=remain_df.label.values)\n",
    "\n",
    "train_df.to_csv(\"Data/train_df_v4.csv\")\n",
    "test_df.to_csv(\"Data/test_df_v4.csv\")\n",
    "dev_df.to_csv(\"Data/dev_df_v4.csv\")\n",
    "\n",
    "#formulate system context pretraining dataset\n",
    "system_context_pretrain_df = pd.concat([system_context_unlbl, train_df])\n",
    "system_context_pretrain_df.to_csv(\"Data/system_context_pretrain_v4.csv\")\n",
    "system_pretrain_train, system_pretrain_validation = train_test_split(system_context_pretrain_df, test_size=0.2, random_state=42)\n",
    "system_pretrain_train.text.to_csv(\"Data/system_pretrain_train_v4.csv\")\n",
    "system_pretrain_validation.text.to_csv(\"Data/system_pretrain_dev_v4.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
